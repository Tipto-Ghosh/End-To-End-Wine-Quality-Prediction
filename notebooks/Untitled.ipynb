{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e018d38-0762-4860-b39e-1478855417bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92825ee0-cc7b-4860-9527-93a0f33c5d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wine type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.036</td>\n",
       "      <td>14.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.99085</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.58</td>\n",
       "      <td>11.1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.035</td>\n",
       "      <td>26.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.99200</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.35</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.368</td>\n",
       "      <td>16.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.28</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>white</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.023</td>\n",
       "      <td>56.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.98958</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.70</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.074</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.99620</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  wine type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0     white            6.0             0.180         0.31             1.4   \n",
       "1     white            5.3             0.395         0.07             1.3   \n",
       "2       red            8.1             0.560         0.28             1.7   \n",
       "3     white            6.4             0.220         0.34             1.4   \n",
       "4       red            9.4             0.270         0.53             2.4   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.036                 14.0                  75.0  0.99085  3.34   \n",
       "1      0.035                 26.0                 102.0  0.99200  3.50   \n",
       "2      0.368                 16.0                  56.0  0.99680  3.11   \n",
       "3      0.023                 56.0                 115.0  0.98958  3.18   \n",
       "4      0.074                  6.0                  18.0  0.99620  3.20   \n",
       "\n",
       "   sulphates  alcohol  quality  \n",
       "0       0.58     11.1        8  \n",
       "1       0.35     10.6        6  \n",
       "2       1.28      9.3        5  \n",
       "3       0.70     11.7        6  \n",
       "4       1.13     12.0        7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"wine.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1cd9022-2c73-4f29-915d-a36aefc4bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['wine type' , 'fixed acidity' , 'sulphates' , \"pH\"] , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87009c9-597f-45c2-9da7-0b3f77477171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column citric acid values with greater than 0.95 is outlier remove all where value crosses the thresold \n",
    "df = df[df['citric acid'] <= 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96fdf36e-7c33-40cd-a750-3f9dfed1aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual sugar column has outlier, remove all rows where values are greater than 25\n",
    "df = df[df['residual sugar'] <= 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cb5434-80c6-4972-b8f4-b5fabb9ddf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total sulfur dioxide has outlier \n",
    "df = df[df['total sulfur dioxide'] <= 280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7214cbad-a7a1-4380-aaab-e71070503a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `density` is not changing for `quality` not an usefull column , drop this column\n",
    "df.drop(columns = ['density'] , axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f5ff190-30d7-4eea-ae9b-9d40aa6c3cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_quality = [3 , 9]\n",
    "# drop these rows where quality is in drop_quality\n",
    "df = df[~df['quality'].isin(drop_quality)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0408fd65-39cf-4d09-b886-7ab8fc7f9b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0 1 2 3 4] ->  [4 5 6 7 8]\n",
    "mapper = {\n",
    "    4 : 0 , 5 : 1 , 6 : 2 , 7 : 3 , 8 : 4\n",
    "}\n",
    "df['quality'] = df['quality'].map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c60f297-c48c-4c5a-a81e-c744dc1815fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seprate X and y \n",
    "X = df.drop(\"quality\" , axis = 1)\n",
    "y = df['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c91b42ac-8294-4b79-a286-b1a1580480f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 2824, 1: 2133, 3: 1078, 0: 215, 4: 193})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f52e901-d00f-4162-98e9-57660ed2e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , stratify = y , test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9db2464-ccc8-44f0-9e14-0e78ae044463",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_cols = ['volatile acidity' , 'residual sugar', 'chlorides']\n",
    "sqrt_cols = ['free sulfur dioxide']\n",
    "other_cols = [col for col in X.columns if col not in log_cols + sqrt_cols] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1df31c44-6322-4d22-8b01-6efc9d6c3a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer , StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbebfaac-7d13-46c6-adab-e528aba97115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define log transformers  \n",
    "log_pipeline = Pipeline(steps = [\n",
    "    (\"log\" , FunctionTransformer(np.log1p , validate = False)) , \n",
    "    (\"scaler\" , StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1facdf7e-d922-4e43-887c-898d12ff631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sqrt transformer with scaling \n",
    "sqrt_pipeline = Pipeline(steps = [\n",
    "    (\"sqrt\" , FunctionTransformer(np.sqrt , validate = False)), \n",
    "    (\"scaler\" , StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd64856e-07d8-48c5-8123-6e544e368f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a scaler for others column\n",
    "scaler_pipeline = Pipeline(steps = [\n",
    "    (\"scaler\" , StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfe8a36c-f4c8-4614-8e92-b1edf97fbc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the column transformer \n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"log\" , log_pipeline , log_cols),\n",
    "        (\"sqrt\" , sqrt_pipeline , sqrt_cols),\n",
    "        (\"others\" , scaler_pipeline , other_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06d0ea44-50e9-49f0-9f1a-b17951f87b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the preprocessing for train data \n",
    "X_train_transformed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "872a7b26-0ecf-4ca2-9563-5dd616644f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, precision_score, recall_score, f1_score, roc_auc_score,roc_curve \n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "436aa042-a5b2-46fb-938b-b982d91fca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(multi_class = \"multinomial\", solver = \"lbfgs\", max_iter = 500),\n",
    "    \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(eval_metric=\"mlogloss\", use_label_encoder=False),\n",
    "    \"CatBoosting Classifier\": CatBoostClassifier(verbose = False),\n",
    "    \"Support Vector Classifier\": SVC(probability = True),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0e42eaf-4ced-464f-a3e7-20582bea27bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dd7aa60-8d6b-4769-a8e0-ba3a4d1cb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(true, predicted, predicted_proba=None):\n",
    "    acc = accuracy_score(true, predicted)  \n",
    "    f1 = f1_score(true, predicted, average=\"weighted\")  \n",
    "    precision = precision_score(true, predicted, average=\"weighted\")\n",
    "    recall = recall_score(true, predicted, average=\"weighted\")\n",
    "    \n",
    "    # ROC-AUC only works with probability scores + needs `multi_class` flag\n",
    "    roc_auc = None\n",
    "    if predicted_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(true, predicted_proba, multi_class=\"ovr\", average=\"weighted\")\n",
    "        except Exception:\n",
    "            roc_auc = None  # In case some models donâ€™t support probability outputs\n",
    "    \n",
    "    return acc, f1, precision, recall, roc_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5e5073c-8f1b-4576-badf-524120e7ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(X_train, y_train, model_dict): \n",
    "    results = [] \n",
    "    \n",
    "    for model_name, model_obj in model_dict.items(): \n",
    "        print(f\"--------------------------- Model: {model_name} ----------------------\")\n",
    "\n",
    "        # Pipeline with SMOTEENN + model\n",
    "        pipeline = Pipeline(steps=[\n",
    "            (\"smoteen\", SMOTEENN(random_state=42, sampling_strategy=\"minority\")),\n",
    "            (model_name, model_obj)\n",
    "        ])\n",
    "\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        scores = cross_val_score(\n",
    "            pipeline, X_train, y_train, cv=cv, scoring=\"accuracy\", n_jobs=-1\n",
    "        )\n",
    "\n",
    "        results.append({\n",
    "            \"Model Name\": model_name,\n",
    "            \"Mean CV (Accuracy)\": scores.mean(),\n",
    "            \"Std CV\": scores.std()\n",
    "        })\n",
    "\n",
    "        print(results[-1])\n",
    "\n",
    "    report = pd.DataFrame(results).sort_values(\n",
    "        by=[\"Mean CV (Balanced Accuracy)\"], ascending=False\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2243e-f684-45af-a7ad-add0b90fef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Model: Random Forest ----------------------\n",
      "{'Model Name': 'Random Forest', 'Mean CV (Accuracy)': 0.4635200060267627, 'Std CV': 0.012736823569282608}\n",
      "--------------------------- Model: Decision Tree ----------------------\n",
      "{'Model Name': 'Decision Tree', 'Mean CV (Accuracy)': 0.4528513178834763, 'Std CV': 0.011383011226525203}\n",
      "--------------------------- Model: Gradient Boosting ----------------------\n",
      "{'Model Name': 'Gradient Boosting', 'Mean CV (Accuracy)': 0.4375205522021225, 'Std CV': 0.017648512155452434}\n",
      "--------------------------- Model: Logistic Regression ----------------------\n",
      "{'Model Name': 'Logistic Regression', 'Mean CV (Accuracy)': 0.2574698897290782, 'Std CV': 0.003952925653408192}\n",
      "--------------------------- Model: K-Neighbors Classifier ----------------------\n",
      "{'Model Name': 'K-Neighbors Classifier', 'Mean CV (Accuracy)': 0.4062847833661352, 'Std CV': 0.008587278812715182}\n",
      "--------------------------- Model: XGBClassifier ----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\end-to-end-machine-learning-project\\End-To-End-Wine-Quality-Prediction\\wineEnv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:516: FitFailedWarning: \n",
      "1 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\end-to-end-machine-learning-project\\End-To-End-Wine-Quality-Prediction\\wineEnv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"E:\\end-to-end-machine-learning-project\\End-To-End-Wine-Quality-Prediction\\wineEnv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\end-to-end-machine-learning-project\\End-To-End-Wine-Quality-Prediction\\wineEnv\\Lib\\site-packages\\imblearn\\pipeline.py\", line 526, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **last_step_params[\"fit\"])\n",
      "  File \"E:\\end-to-end-machine-learning-project\\End-To-End-Wine-Quality-Prediction\\wineEnv\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\end-to-end-machine-learning-project\\End-To-End-Wine-Quality-Prediction\\wineEnv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1641, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [1 2 3 4]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model Name': 'XGBClassifier', 'Mean CV (Accuracy)': nan, 'Std CV': nan}\n",
      "--------------------------- Model: CatBoosting Classifier ----------------------\n"
     ]
    }
   ],
   "source": [
    "base_model_report = model_evaluation(X_train = X_train_transformed , y_train = y_train , model_dict = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102de0a1-6b11-41dc-b963-bd1fc84e4d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
